#!/usr/bin/env python3
"""
APIæµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•ç½‘é¡µçˆ¬è™«APIçš„åŠŸèƒ½
"""

import requests
import json
import time

def test_health():
    """æµ‹è¯•å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        response = requests.get('http://localhost:5000/health')
        print("ğŸ” å¥åº·æ£€æŸ¥æµ‹è¯•:")
        print(f"çŠ¶æ€ç : {response.status_code}")
        print(f"å“åº”: {response.json()}")
        return response.status_code == 200
    except Exception as e:
        print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_crawl(url):
    """æµ‹è¯•çˆ¬å–åŠŸèƒ½"""
    try:
        data = {'url': url}
        response = requests.post(
            'http://localhost:5000/crawl',
            headers={'Content-Type': 'application/json'},
            json=data
        )
        
        print(f"\nğŸ•·ï¸ çˆ¬å–æµ‹è¯• - {url}:")
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            if result['success']:
                print(f"âœ… çˆ¬å–æˆåŠŸï¼Œå…±è·å– {len(result['content'])} é¡¹å†…å®¹")
                
                # æ˜¾ç¤ºå‰5é¡¹å†…å®¹
                print("\nğŸ“„ å†…å®¹é¢„è§ˆ:")
                for i, item in enumerate(result['content'][:5]):
                    print(f"{i+1}. [{item['type']}] {item['text'][:100]}...")
                    
                if len(result['content']) > 5:
                    print(f"... è¿˜æœ‰ {len(result['content']) - 5} é¡¹å†…å®¹")
            else:
                print(f"âŒ çˆ¬å–å¤±è´¥: {result['error']}")
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.text}")
            
    except Exception as e:
        print(f"âŒ çˆ¬å–æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹APIæµ‹è¯•...")
    
    # æµ‹è¯•å¥åº·æ£€æŸ¥
    if not test_health():
        print("âŒ æœåŠ¡å™¨æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡å™¨")
        return
    
    # æµ‹è¯•çˆ¬å–åŠŸèƒ½
    test_urls = [
        'https://example.com',
        'https://httpbin.org/html',
        'https://news.ycombinator.com'
    ]
    
    for url in test_urls:
        test_crawl(url)
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")

if __name__ == '__main__':
    main() 