# 🧪 完整测试验证指南

## 📋 测试检查清单

### ✅ 第1步：后端API测试（2分钟）

**安装依赖：**
```bash
pip3 install -r requirements.txt
```

**启动服务器：**
```bash
python3 server.py
```

**看到这个界面说明成功：**
```
* Running on all addresses (0.0.0.0)
* Running on http://127.0.0.1:5000
* Running on http://[::]:5000
```

**运行测试脚本：**
```bash
python3 test_api.py
```

**期望看到：**
```
🚀 开始API测试...
🔍 健康检查测试:
状态码: 200
响应: {'message': '服务正常运行', 'status': 'ok'}

🕷️ 爬取测试 - https://example.com:
状态码: 200
✅ 爬取成功，共获取 5 项内容
```

### ✅ 第2步：浏览器手动测试（2分钟）

**打开浏览器测试：**
1. 在新标签页访问：`http://localhost:5000`
2. 应该看到"网页爬虫API服务"页面
3. 访问：`http://localhost:5000/health`
4. 应该看到：`{"status": "ok", "message": "服务正常运行"}`

**用curl测试爬取功能：**
```bash
curl -X POST http://localhost:5000/crawl \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

**期望返回：**
```json
{
  "success": true,
  "content": [
    {
      "type": "页面标题",
      "tag": "title",
      "text": "Example Domain"
    }
  ]
}
```

### ✅ 第3步：浏览器插件测试（3分钟）

**安装插件：**
1. Chrome浏览器 → 地址栏输入 `chrome://extensions/`
2. 开启右上角"开发者模式"
3. 点击"加载已解压的扩展程序"
4. 选择项目文件夹
5. 看到"网页爬虫助手"插件出现

**测试插件功能：**
1. 打开任意网页（如baidu.com）
2. 点击浏览器工具栏的爬虫图标
3. 点击"爬取当前页面"
4. 应该看到爬取结果按类型分段显示

**测试指定URL：**
1. 在插件输入框中输入：`https://example.com`
2. 点击"开始爬取"
3. 应该看到爬取成功的状态提示

### ✅ 第4步：端到端测试（5分钟）

**测试各种网站：**
```
✅ 简单网站：https://example.com
✅ 新闻网站：https://news.ycombinator.com
✅ 搜索网站：https://www.baidu.com
✅ 技术网站：https://github.com
```

**测试各种内容类型：**
- 📝 页面标题 ✅
- 🔖 各级标题 ✅
- 📄 段落内容 ✅
- 🔗 链接 ✅
- 🖼️ 图片 ✅
- 📊 表格 ✅

## 🔍 故障排除

### 问题1：python命令不存在
**解决方案：**
```bash
# 使用python3替代python
python3 server.py
```

### 问题2：依赖安装失败
**解决方案：**
```bash
# 升级pip
pip3 install --upgrade pip

# 重新安装依赖
pip3 install -r requirements.txt
```

### 问题3：端口被占用
**解决方案：**
```bash
# 查看端口占用
lsof -i :5000

# 杀死占用进程
kill -9 进程ID
```

### 问题4：插件无法连接服务器
**检查项：**
1. 服务器是否正在运行
2. popup.js中的SERVER_URL是否正确
3. 是否有防火墙阻止连接

### 问题5：某些网站爬取失败
**原因：**
- 网站有防爬虫保护
- 需要登录才能访问
- 网站使用了复杂的JavaScript渲染

**这是正常现象，不影响整体功能**

## 📊 性能测试

### 响应时间测试
```bash
# 测试健康检查接口
time curl http://localhost:5000/health

# 测试爬取接口
time curl -X POST http://localhost:5000/crawl \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

### 预期性能指标
- 健康检查：< 50ms
- 简单页面爬取：< 2秒
- 复杂页面爬取：< 5秒

## 🎯 测试结果判断

### ✅ 测试通过标准
1. API健康检查返回200状态码
2. 能够成功爬取至少3个不同网站
3. 浏览器插件能正常加载和使用
4. 爬取结果按类型正确分段显示

### ❌ 需要修复的问题
1. 服务器无法启动
2. API返回500错误
3. 插件无法加载
4. 爬取结果为空或格式错误

## 🚀 部署前最终检查

### 本地测试通过后，进行部署前检查：
1. 修改popup.js中的SERVER_URL为实际服务器地址
2. 确保所有依赖都已正确安装
3. 测试生产环境的网络连接
4. 备份所有配置文件

### 部署后验证：
1. 访问服务器域名，确认服务正常
2. 使用curl测试API接口
3. 重新打包并安装更新后的插件
4. 进行端到端功能测试

## 📞 技术支持

如果测试过程中遇到问题：
1. 查看控制台日志
2. 检查网络连接
3. 确认配置文件正确
4. 重启服务器和浏览器

**测试通过后，你的网页爬虫插件就可以正式使用了！** 